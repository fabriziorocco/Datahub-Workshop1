{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Workshop 1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKT5vZaMqH2_"
      },
      "source": [
        "<h1><center>ESADE Datahub Workshop</center></h1>\n",
        "<h2><center>House Price Prediction</center></h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "708CdovvqH3F"
      },
      "source": [
        "The aim of this project is to build a Machine Learning model in order to predict the appropriate price of a house given a set of features.\n",
        "We decided to divide our analysis into 5 parts:\n",
        " - First look at the problem and general understanding of the variables;\n",
        " - Study the main variable (\"SalePrice\"); \n",
        " - Study how the main variable is related to the other feature;\n",
        " - Data Preprocessing:\n",
        " - Build a model in order to predict SalePrice \n",
        " \n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WPyQ2XXqH3G"
      },
      "source": [
        "#### Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CuqHqZTvqH3H"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.stats import norm\n",
        "%matplotlib inline\n",
        "from sklearn.model_selection import cross_val_score, train_test_split, KFold, cross_val_predict\n",
        "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
        "from sklearn.linear_model import LinearRegression, RidgeCV, Lasso, ElasticNetCV, BayesianRidge, LassoLarsIC\n",
        "from sklearn.metrics import mean_squared_error, make_scorer\n",
        "from sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\n",
        "from sklearn.kernel_ridge import KernelRidge\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
        "import math\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwqvq6LBqH3J"
      },
      "source": [
        "result = pd.read_csv(\"/content/train.csv\")\n",
        "result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsSe6DCHE9FY"
      },
      "source": [
        "numeric = result.select_dtypes(include=np.number)\n",
        "numeric.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8KPp8NEqH3M"
      },
      "source": [
        "result.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYu4iwEiqH3N"
      },
      "source": [
        "result.tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhBYcTjdqH3O"
      },
      "source": [
        "result.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OG4wG-e1qH3P"
      },
      "source": [
        "result.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyiKeU_8qH3Q"
      },
      "source": [
        "# Our initial considerations \n",
        "Looking forward to our columns, we found some variables which can have an high correlation with our main variable SalePrice:\n",
        "- __Year Built__\n",
        "- __TotalBsmtSF__\n",
        "- __GrLivArea__\n",
        "- __PoolArea__\n",
        "\n",
        "These are variables related to the conditions of the building, its age and some \"extra luxury\" features such as __PoolArea__. \n",
        "In principle they are all characteristics which can rise the price of an house. \n",
        "Another theory we suggested was to consider mainly the \"inner\" part of the house, such as __KitchenQual__ or __CentralAir__, but these could be too general features which mainly all the houses can have.\n",
        "\n",
        "Now, with these prior hypotesis, let's dive into the \"__SalePrice__\" analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pFwTuYDqH3Q"
      },
      "source": [
        "# SalePrice Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yv19xzembbgB"
      },
      "source": [
        "y = result['SalePrice']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uhjGeubqH3Q"
      },
      "source": [
        "y.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LoydQPRgqH3S"
      },
      "source": [
        "sns.distplot(result['SalePrice']);\n",
        "print(\"Skewness coeff. is: %f\" % result['SalePrice'].skew())\n",
        "print(\"Kurtosis coeff. is: %f\" % result['SalePrice'].kurt())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-Sn3wZaqH3U"
      },
      "source": [
        "**These** measures of symmetry are useful in order to understand the symmetry of the distribution of our main variable.\n",
        "Our distribution is highly skewed and present a longer tail on the right. \n",
        "The high value of kurtosis can determine an higher probability of outliers values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jV-ULAwuqH3U"
      },
      "source": [
        "# The other variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fNaxYOVqH3U"
      },
      "source": [
        "data_year_trend = pd.concat([result['SalePrice'], result['YearBuilt']], axis=1)\n",
        "data_year_trend.plot.scatter(x='YearBuilt', y='SalePrice', ylim=(0,800000));"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYEWBSoKqH3V"
      },
      "source": [
        "data_bsmt_trend = pd.concat([result['SalePrice'], result['TotalBsmtSF']], axis=1)\n",
        "data_bsmt_trend.plot.scatter(x='TotalBsmtSF', y='SalePrice', ylim=(0,800000));"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJVzIhIEqH3V"
      },
      "source": [
        "data_GrLivArea_trend = pd.concat([result['SalePrice'], result['GrLivArea']], axis=1)\n",
        "data_GrLivArea_trend.plot.scatter(x='GrLivArea', y='SalePrice', ylim=(0,800000));"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-aGzopaqH3V"
      },
      "source": [
        "data_PoolArea_trend = pd.concat([result['SalePrice'], result['PoolArea']], axis=1)\n",
        "data_PoolArea_trend.plot.scatter(x='PoolArea', y='SalePrice', ylim=(0,800000));"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qD6V2WlqH3W"
      },
      "source": [
        "data = pd.concat([result['SalePrice'], result['OverallQual']], axis=1)\n",
        "f, ax = plt.subplots(figsize=(8, 6))\n",
        "fig = sns.boxplot(x='OverallQual', y=\"SalePrice\", data=data)\n",
        "fig.axis(ymin=0, ymax=800000);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_G-OlpkrqH3X"
      },
      "source": [
        "By these analysis we discovered that our previsions were quite correct.\n",
        "\n",
        "__Year Built__ seems to have a slight relation with our main variable, and people, as we thought, tend to buy newer houses. \n",
        "\n",
        " __TotalBsmtSF__ and __GrLivArea__ there seems be a stronger relation with __SalePrice__. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ue579MOzqH3X"
      },
      "source": [
        "# Heatmap Correlation Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXUJIMQxqH3X"
      },
      "source": [
        "corr_matrix = result.corr()\n",
        "f, ax1 = plt.subplots(figsize=(12,9)) \n",
        "ax1=sns.heatmap(corr_matrix,vmax = 0.9); "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZslMFWzqH3Y"
      },
      "source": [
        "Using this kind of plot we can deduce if there's some collinearity between 2 or more variables.\n",
        "In particoular, there are some white blocks which have to be analyzed:\n",
        "1. __GarageYrBlt__ and __YearBuilt__\n",
        "2. __TotRmsAbvGrd__ and __GrLivArea__\n",
        "3. __TotalBsmtSF__ and __X1stFlrSF__\n",
        "4. __GarageArea__ and __GarageCars__\n",
        " \n",
        "Knowing the meaning of these pairs of variables seems trivial to notice a collinearity between pairs \"1\", \"3\" and \"4\".\n",
        "For the \"2\" pair the difference is slightly more subtle because the house area and the total number of rooms, not always are related. \n",
        "For example two houses with the same living area can be inhabited by different number of peoples and so the actual disposition/number of the rooms can be different.\n",
        "\n",
        "Let's restrict our matrix a bit more."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkTEG4vnqH3Y"
      },
      "source": [
        "corrmat = result.corr()\n",
        "top_corr_features = corrmat.index[abs(corrmat[\"SalePrice\"])>0.5]\n",
        "plt.figure(figsize=(9,9))\n",
        "g = sns.heatmap(result[top_corr_features].corr(),annot=True,cmap=\"RdYlGn\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "Gy3_fYryqH3Y"
      },
      "source": [
        "var = result[result.columns[1:]].corr()['SalePrice'][:]\n",
        "var"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOgGehV9qH3Z"
      },
      "source": [
        "sns.set()\n",
        "cols = ['SalePrice', 'OverallQual', 'GrLivArea', 'GarageCars', 'TotalBsmtSF', 'FullBath', 'YearBuilt']\n",
        "sns.pairplot(result[cols], height = 2.5)\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6DCkbYeXqH3Z"
      },
      "source": [
        "# Dealing with Null Values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPj8sG7SqH3Z"
      },
      "source": [
        "Now our goal is to deal with null values and try to understand for each one what can we do: drop or fill them? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQtPn6qIqH3a"
      },
      "source": [
        "total_null = result.isnull().sum().sort_values(ascending=False) #First sum and order all null values for each variable\n",
        "percentage = (result.isnull().sum()/result.isnull().count()).sort_values(ascending=False) #Get the percentage\n",
        "missing_data = pd.concat([total_null, percentage], axis=1, keys=['Total', 'Percentage'])\n",
        "missing_data.head(20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ceXfrbkbqH3a"
      },
      "source": [
        "We have to do some considerations. \n",
        "Let's divide our null values into 2 groups:\n",
        " - __PoolQC__, __MiscFeature__, __Alley__, __Fence__, __FireplaceQu__ and __LotFrontage__.\n",
        "These are all variables which presents many null values. In general, by common opinion, we can discourage variables which have more than 15% of missing values. \n",
        "These are not vital information for someone who wants to buy an house, such as __FireplaceQu__ or, for example, many houses doesn't have an __Alley__ access. We can drop them.\n",
        "\n",
        "The second group:\n",
        " - __GarageX__ properties\n",
        "If we look carefully, all of these variables have the same number of null values! Maybe this can be a strange coincidence, or just that they all refer to the same variable Garage, in which \"Na\" means \"There is no Garage\". The same occurs for __BsmtX__ and MasVnr__, which means that we will have to deal with them afterwards."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "lTs1_cZRqH3a"
      },
      "source": [
        "result = result.drop((missing_data[missing_data[\"Percentage\"] > 0.15]).index,1) \n",
        "result.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLxQf50GqH3b"
      },
      "source": [
        "# Categorical vs Numerical Variables\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnytfBCxXs2h"
      },
      "source": [
        "### Handling Correlation and Variance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tT8lplX3Ri6a"
      },
      "source": [
        "In the following block we are going to remove some columns.\n",
        "Let's see why\n",
        "\n",
        "- **Zero Variance Problem**: If the variance is low or close to zero, then a feature is approximately constant and will not improve the performance of the model. In that case, it should be removed.\n",
        "- **Multicollinearity**: It is the occurrence of high intercorrelations among two or more independent variables in a multiple regression model. Why avoid that? \n",
        "- **Other variables are composed by sub-features**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXDKqTj3qH3b"
      },
      "source": [
        "# What I mean by Zero Variance Variables\n",
        "result['MiscVal'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "LW7CztmzqH3b"
      },
      "source": [
        "#Zero variance\n",
        "del result[\"KitchenAbvGr\"]\n",
        "del result[\"YrSold\"]\n",
        "del result[\"MoSold\"]\n",
        "del result[\"MiscVal\"]\n",
        "del result[\"ScreenPorch\"]\n",
        "del result[\"X3SsnPorch\"]\n",
        "del result[\"BsmtHalfBath\"]\n",
        "del result[\"LowQualFinSF\"]\n",
        "del result[\"OverallCond\"]\n",
        "del result[\"EnclosedPorch\"]\n",
        "del result[\"MSSubClass\"]\n",
        "del result[\"X1stFlrSF\"]\n",
        "del result[\"YearBuilt\"]\n",
        "del result[\"YearRemodAdd\"] \n",
        "del result[\"BsmtFinSF2\"] \n",
        "del result[\"PoolArea\"] \n",
        "del result[\"GarageYrBlt\"] \n",
        "del result[\"GarageCond\"] \n",
        "del result[\"Street\"]\n",
        "del result[\"LandContour\"]\n",
        "del result[\"Utilities\"]\n",
        "del result[\"LandSlope\"]\n",
        "del result[\"Condition2\"]\n",
        "del result[\"RoofMatl\"]\n",
        "del result[\"BsmtFinType2\"] \n",
        "del result[\"Electrical\"] \n",
        "del result[\"Condition1\"]\n",
        "del result[\"BldgType\"]\n",
        "del result[\"HouseStyle\"]\n",
        "del result[\"Exterior1st\"]\n",
        "del result[\"Exterior2nd\"]\n",
        "del result[\"Foundation\"]\n",
        "del result[\"CentralAir\"]\n",
        "del result[\"Functional\"]\n",
        "del result[\"SaleType\"]\n",
        "del result[\"SaleCondition\"]\n",
        "del result[\"RoofStyle\"]\n",
        "del result['ExterCond']\n",
        "del result['BsmtCond']\n",
        "\n",
        "#Multicollinearity\n",
        "del result[\"GarageArea\"] \n",
        "del result[\"TotRmsAbvGrd\"] \n",
        "\n",
        "#Variable composition\n",
        "del result[\"BsmtFinSF1\"] #Because BsmtFinSF1 + BsmtUnfSF + BsmtFinSF2 = TotalBsmtSF\n",
        "del result[\"BsmtUnfSF\"] #Because BsmtFinSF1 + BsmtUnfSF + BsmtFinSF2 = TotalBsmtSF"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9ldyMAqXgiw"
      },
      "source": [
        "### Encoding of Rank Categorical Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1IHNiiXLX8zr"
      },
      "source": [
        "result['ExterQual'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24edHEPwqH3c"
      },
      "source": [
        "#Here we encode ExterQual in a rank\n",
        "result.loc[result['ExterQual'] == \"Ex\", 'ExterQual'] = 5\n",
        "result.loc[result['ExterQual'] == \"Gd\", 'ExterQual'] = 4\n",
        "result.loc[result['ExterQual'] == \"TA\", 'ExterQual'] = 3\n",
        "result.loc[result['ExterQual'] == \"Fa\", 'ExterQual'] = 2\n",
        "result.loc[result['ExterQual'] == \"Po\", 'ExterQual'] = 1\n",
        "result['ExterQual']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfY3dCZKqH3d"
      },
      "source": [
        "#Here we encode HeatingQC in Rank\n",
        "result.loc[result['HeatingQC'] == \"Ex\", 'HeatingQC'] = 5\n",
        "result.loc[result['HeatingQC'] == \"Gd\", 'HeatingQC'] = 4\n",
        "result.loc[result['HeatingQC'] == \"TA\", 'HeatingQC'] = 3\n",
        "result.loc[result['HeatingQC'] == \"Fa\", 'HeatingQC'] = 2\n",
        "result.loc[result['HeatingQC'] == \"Po\", 'HeatingQC'] = 1\n",
        "result['HeatingQC']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9Sl2uzpqH3d"
      },
      "source": [
        "#Here we encode BsmtFinType1 in Rank\n",
        "result.loc[result['BsmtFinType1'] == \"GLQ\", 'BsmtFinType1'] = 6\n",
        "result.loc[result['BsmtFinType1'] == \"ALQ\", 'BsmtFinType1'] = 5\n",
        "result.loc[result['BsmtFinType1'] == \"BLQ\", 'BsmtFinType1'] = 4\n",
        "result.loc[result['BsmtFinType1'] == \"Rec\", 'BsmtFinType1'] = 3\n",
        "result.loc[result['BsmtFinType1'] == \"LwQ\", 'BsmtFinType1'] = 2\n",
        "result.loc[result['BsmtFinType1'] == \"Unf\", 'BsmtFinType1'] = 1\n",
        "result['BsmtFinType1'].fillna(0, inplace= True)\n",
        "result['BsmtFinType1']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sj__MM29qH3e"
      },
      "source": [
        "#Here we encode BsmtQual in Rank\n",
        "result.loc[result['BsmtQual'] == \"Ex\", 'BsmtQual'] = 5\n",
        "result.loc[result['BsmtQual'] == \"Gd\", 'BsmtQual'] = 4\n",
        "result.loc[result['BsmtQual'] == \"TA\", 'BsmtQual'] = 3\n",
        "result.loc[result['BsmtQual'] == \"Fa\", 'BsmtQual'] = 2\n",
        "result.loc[result['BsmtQual'] == \"Po\", 'BsmtQual'] = 1\n",
        "result['BsmtQual'].fillna(0, inplace= True)\n",
        "result['BsmtQual']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJnylW7WqH3f"
      },
      "source": [
        "#Here we encode KitchenQual in Rank\n",
        "result.loc[result['KitchenQual'] == \"Ex\", 'KitchenQual'] = 4\n",
        "result.loc[result['KitchenQual'] == \"Gd\", 'KitchenQual'] = 3\n",
        "result.loc[result['KitchenQual'] == \"TA\", 'KitchenQual'] = 2\n",
        "result.loc[result['KitchenQual'] == \"Fa\", 'KitchenQual'] = 1\n",
        "result['KitchenQual']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkBinaTRqH3f"
      },
      "source": [
        "#Here we encode BsmtExposure in Rank\n",
        "result.loc[result['BsmtExposure'] == \"Gd\", 'BsmtExposure'] = 4\n",
        "result.loc[result['BsmtExposure'] == \"Av\", 'BsmtExposure'] = 3\n",
        "result.loc[result['BsmtExposure'] == \"Mn\", 'BsmtExposure'] = 2\n",
        "result.loc[result['BsmtExposure'] == \"No\", 'BsmtExposure'] = 1\n",
        "result['BsmtExposure'].fillna(0, inplace= True)\n",
        "result['BsmtExposure']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98xVl0ToqH3g"
      },
      "source": [
        "#Here we encode GarageQual in Rank\n",
        "result.loc[result['GarageQual'] == \"Ex\", 'GarageQual'] = 5\n",
        "result.loc[result['GarageQual'] == \"Gd\", 'GarageQual'] = 4\n",
        "result.loc[result['GarageQual'] == \"TA\", 'GarageQual'] = 3\n",
        "result.loc[result['GarageQual'] == \"Fa\", 'GarageQual'] = 2\n",
        "result.loc[result['GarageQual'] == \"Po\", 'GarageQual'] = 1\n",
        "result['GarageQual'].fillna(0, inplace= True)\n",
        "result['GarageQual']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDlO2dDsqH3g"
      },
      "source": [
        "del result[\"GarageQual\"] #Large majority of values are 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dYrswSZqH3g"
      },
      "source": [
        "#Here we encode GarageFinish in Rank\n",
        "result.loc[result['GarageFinish'] == \"Fin\", 'GarageFinish'] = 4\n",
        "result.loc[result['GarageFinish'] == \"RFn\", 'GarageFinish'] = 3\n",
        "result.loc[result['GarageFinish'] == \"Unf\", 'GarageFinish'] = 2\n",
        "result['GarageFinish'].fillna(0, inplace= True)\n",
        "result['GarageFinish']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPnsLOwLqH3h"
      },
      "source": [
        "#HERE WE FILL THE LAST NAs IN THOSE VARIABLES WHICH WE CAN NOT RANK\n",
        "result['MasVnrType'].fillna(\"None\", inplace= True)\n",
        "result['MasVnrArea'].fillna(0, inplace= True)\n",
        "result['GarageType'].fillna(\"No Garage\", inplace= True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8jNkUgztqH3i"
      },
      "source": [
        "# Outliers Detection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ytLvtfq1XYa"
      },
      "source": [
        "#Take only numerical variables for outliers detection\n",
        "numeric = result.select_dtypes(include=np.number) \n",
        "n_features = numeric.columns\n",
        "n_features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EI86yDH9ZK9r"
      },
      "source": [
        "### IQR analysis\n",
        "The Interquartile range formula measures the variability, based on dividing an ordered set of data into quartiles."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMrt2Xktuk9Y"
      },
      "source": [
        "Q1 = result[n_features].quantile(0.25)\n",
        "Q3 = result[n_features].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "result = result[~((result[n_features] < (Q1 - 1.5 * IQR)) |(result[n_features] > (Q3 + 1.5 * IQR))).any(axis=1)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HU1_gdOz1JBG"
      },
      "source": [
        "# Difference between previous columns and new numerical\n",
        "result = result[result.columns.difference(numeric.columns)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dHJ3ToTZl3Y"
      },
      "source": [
        "### Normalization\n",
        "\n",
        "Do we actually need that? \n",
        "Normalization is a good technique to use when we do not know the distribution of your data or when you know the distribution is not bell-shaped (Gaussian)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26rNY2b5zKh5"
      },
      "source": [
        "#numeric = (numeric-numeric.mean())/numeric.std() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0n1Mt6e0vIL"
      },
      "source": [
        "#Concatenate Result + Numeric and reset indexes\n",
        "result = pd.concat([result, numeric], axis=1)\n",
        "result = result.reset_index()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2-nIRPiIH_o"
      },
      "source": [
        "result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPyQeJud2w6Y"
      },
      "source": [
        "#Adjust result df removing some NaN's rows obtained from concatenation and the index columnn.\n",
        "result = result[result[\"BsmtExposure\"].notna()]\n",
        "del result['index']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GS9frkaAISTu"
      },
      "source": [
        "### Dummy Variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xS4ArT5xz2pp"
      },
      "source": [
        "data_train = pd.get_dummies(result)\n",
        "data_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvZZh8RLHZ7s"
      },
      "source": [
        "data_train = data_train.fillna(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxDCN7bFqH3k"
      },
      "source": [
        "y = data_train['SalePrice']\n",
        "data = data_train.drop(['SalePrice'], axis=1)\n",
        "xtrain, xvalid, ytrain, yvalid = train_test_split(data, y, test_size=0.3, random_state=40)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3AAucyG-qH3m"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhJiVREBqH3r"
      },
      "source": [
        "### Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Br6Bj4C9qH3s"
      },
      "source": [
        "regressor = RandomForestRegressor(n_estimators=300, random_state=0)\n",
        "regressor.fit(xtrain,ytrain)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pna_shcMJEmV"
      },
      "source": [
        "predicted = regressor.predict(xvalid)\n",
        "predicted"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5glET0ZHJ-O5"
      },
      "source": [
        "from sklearn import metrics\n",
        "print('MAE:', metrics.mean_absolute_error(yvalid, predicted))\n",
        "print('MSE:', metrics.mean_squared_error(yvalid, predicted))\n",
        "print('RMSE:', np.sqrt(metrics.mean_squared_error(yvalid, predicted)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvBXiz-wqH3q"
      },
      "source": [
        "### Gradient Boosting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atUg2zW3qH3r"
      },
      "source": [
        "GBoost = GradientBoostingRegressor(n_estimators=5000, learning_rate=0.05,\n",
        "                                   max_depth=4, max_features='sqrt',\n",
        "                                   min_samples_leaf=15, min_samples_split=10, \n",
        "                                   loss='huber', random_state =5)\n",
        "GBoost.fit(xtrain, ytrain)\n",
        "rmse = math.sqrt(mean_squared_error(yvalid, GBoost.predict(xvalid)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnXW7LY0LVJb"
      },
      "source": [
        "predicted = GBoost.predict(xvalid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcQQRuXOqH3r"
      },
      "source": [
        "print('MAE:', metrics.mean_absolute_error(yvalid, predicted))\n",
        "print(\"RMSE: %.4f\" % rmse)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JjCtHlekf2I"
      },
      "source": [
        "# Conclusion and further improvements"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1y2qCUsjkjiT"
      },
      "source": [
        "How can we improve our research ?"
      ]
    }
  ]
}